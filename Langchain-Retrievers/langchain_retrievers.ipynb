{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install langchain chromadb faiss-cpu openai tiktoken langchain_openai langchain-community wikipedia"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "defOdsii6Uow",
    "outputId": "0efcbaa6-b005-421d-869d-2b5a605526fb"
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.4)\n",
      "Collecting chromadb\n",
      "  Downloading chromadb-1.4.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.15.0)\n",
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.12.0)\n",
      "Collecting langchain_openai\n",
      "  Downloading langchain_openai-1.1.7-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting wikipedia\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.1 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.2.7)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.6)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Downloading build-1.4.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting pybase64>=1.4.1 (from chromadb)\n",
      "  Downloading pybase64-1.4.3-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.40.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.0.2)\n",
      "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.15.0)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.39.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.2)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Downloading pypika-0.50.0-py2.py3-none-any.whl.metadata (51 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m52.0/52.0 kB\u001B[0m \u001B[31m3.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.76.0)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.21.1)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Downloading kubernetes-35.0.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (9.1.2)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.0.3)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.2.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.5)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.26.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2025.11.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2.32.4)\n",
      "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n",
      "  Downloading langchain_classic-1.0.1-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.45)\n",
      "Collecting requests>=2.26.0 (from tiktoken)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.3)\n",
      "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.4)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from wikipedia) (4.13.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.2-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.30.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: urllib3!=2.6.0,>=1.24.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.5.0)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Collecting langchain-text-splitters<2.0.0,>=1.1.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community)\n",
      "  Downloading langchain_text_splitters-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (1.33)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.13.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (4.0.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.6)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.3.3)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.12.19)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.72.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.39.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.39.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.39.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_proto-1.39.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_sdk-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.60b1 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.4.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.13.2->chromadb) (0.36.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.3.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.7.1)\n",
      "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.22.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
      "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->wikipedia) (2.8.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.20.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.2.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.1->langchain) (3.0.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Downloading chromadb-1.4.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m21.1/21.1 MB\u001B[0m \u001B[31m39.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.8 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m23.8/23.8 MB\u001B[0m \u001B[31m92.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading langchain_openai-1.1.7-py3-none-any.whl (84 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m84.8/84.8 kB\u001B[0m \u001B[31m7.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.5/2.5 MB\u001B[0m \u001B[31m88.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m278.2/278.2 kB\u001B[0m \u001B[31m24.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading build-1.4.0-py3-none-any.whl (24 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading kubernetes-35.0.0-py2.py3-none-any.whl (2.0 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.0/2.0 MB\u001B[0m \u001B[31m77.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading langchain_classic-1.0.1-py3-none-any.whl (1.0 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.0/1.0 MB\u001B[0m \u001B[31m66.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m17.4/17.4 MB\u001B[0m \u001B[31m76.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.39.1-py3-none-any.whl (19 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.39.1-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.39.1-py3-none-any.whl (72 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m72.5/72.5 kB\u001B[0m \u001B[31m6.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading opentelemetry_sdk-1.39.1-py3-none-any.whl (132 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m132.6/132.6 kB\u001B[0m \u001B[31m11.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading opentelemetry_api-1.39.1-py3-none-any.whl (66 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m66.4/66.4 kB\u001B[0m \u001B[31m6.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl (219 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m220.0/220.0 kB\u001B[0m \u001B[31m17.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m105.4/105.4 kB\u001B[0m \u001B[31m10.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading pybase64-1.4.3-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m71.6/71.6 kB\u001B[0m \u001B[31m6.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading pypika-0.50.0-py2.py3-none-any.whl (60 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m60.6/60.6 kB\u001B[0m \u001B[31m5.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m64.7/64.7 kB\u001B[0m \u001B[31m6.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Downloading langchain_text_splitters-1.1.0-py3-none-any.whl (34 kB)\n",
      "Downloading marshmallow-3.26.2-py3-none-any.whl (50 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m51.0/51.0 kB\u001B[0m \u001B[31m4.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m46.0/46.0 kB\u001B[0m \u001B[31m3.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m86.8/86.8 kB\u001B[0m \u001B[31m8.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Building wheels for collected packages: wikipedia\n",
      "  Building wheel for wikipedia (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=c1430fdb6d4bd4aa73cb1eb510d5096943ca7d8a67afc3811a21bda53e9fc4dd\n",
      "  Stored in directory: /root/.cache/pip/wheels/63/47/7c/a9688349aa74d228ce0a9023229c6c0ac52ca2a40fe87679b8\n",
      "Successfully built wikipedia\n",
      "Installing collected packages: pypika, durationpy, requests, pyproject_hooks, pybase64, opentelemetry-proto, mypy-extensions, marshmallow, humanfriendly, faiss-cpu, bcrypt, backoff, wikipedia, typing-inspect, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, build, opentelemetry-semantic-conventions, onnxruntime, kubernetes, dataclasses-json, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-grpc, langchain-text-splitters, langchain_openai, langchain-classic, chromadb, langchain-community\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.32.4\n",
      "    Uninstalling requests-2.32.4:\n",
      "      Successfully uninstalled requests-2.32.4\n",
      "  Attempting uninstall: opentelemetry-proto\n",
      "    Found existing installation: opentelemetry-proto 1.37.0\n",
      "    Uninstalling opentelemetry-proto-1.37.0:\n",
      "      Successfully uninstalled opentelemetry-proto-1.37.0\n",
      "  Attempting uninstall: opentelemetry-exporter-otlp-proto-common\n",
      "    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.37.0\n",
      "    Uninstalling opentelemetry-exporter-otlp-proto-common-1.37.0:\n",
      "      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.37.0\n",
      "  Attempting uninstall: opentelemetry-api\n",
      "    Found existing installation: opentelemetry-api 1.37.0\n",
      "    Uninstalling opentelemetry-api-1.37.0:\n",
      "      Successfully uninstalled opentelemetry-api-1.37.0\n",
      "  Attempting uninstall: opentelemetry-semantic-conventions\n",
      "    Found existing installation: opentelemetry-semantic-conventions 0.58b0\n",
      "    Uninstalling opentelemetry-semantic-conventions-0.58b0:\n",
      "      Successfully uninstalled opentelemetry-semantic-conventions-0.58b0\n",
      "  Attempting uninstall: opentelemetry-sdk\n",
      "    Found existing installation: opentelemetry-sdk 1.37.0\n",
      "    Uninstalling opentelemetry-sdk-1.37.0:\n",
      "      Successfully uninstalled opentelemetry-sdk-1.37.0\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
      "google-adk 1.21.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.39.1 which is incompatible.\n",
      "google-adk 1.21.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
      "opentelemetry-exporter-gcp-logging 1.11.0a0 requires opentelemetry-sdk<1.39.0,>=1.35.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
      "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.39.1 which is incompatible.\n",
      "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.39.1 which is incompatible.\n",
      "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\u001B[0m\u001B[31m\n",
      "\u001B[0mSuccessfully installed backoff-2.2.1 bcrypt-5.0.0 build-1.4.0 chromadb-1.4.1 coloredlogs-15.0.1 dataclasses-json-0.6.7 durationpy-0.10 faiss-cpu-1.13.2 humanfriendly-10.0 kubernetes-35.0.0 langchain-classic-1.0.1 langchain-community-0.4.1 langchain-text-splitters-1.1.0 langchain_openai-1.1.7 marshmallow-3.26.2 mypy-extensions-1.1.0 onnxruntime-1.23.2 opentelemetry-api-1.39.1 opentelemetry-exporter-otlp-proto-common-1.39.1 opentelemetry-exporter-otlp-proto-grpc-1.39.1 opentelemetry-proto-1.39.1 opentelemetry-sdk-1.39.1 opentelemetry-semantic-conventions-0.60b1 posthog-5.4.0 pybase64-1.4.3 pypika-0.50.0 pyproject_hooks-1.2.0 requests-2.32.5 typing-inspect-0.9.0 wikipedia-1.4.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Wikipedia Retriever"
   ],
   "metadata": {
    "id": "b1Fe61XA69FR"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_community.retrievers import WikipediaRetriever"
   ],
   "metadata": {
    "id": "tVlVrUuQ6cCC"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Initialize the retriever (optional: set language and top_k)\n",
    "retriever = WikipediaRetriever(top_k_results=2, lang=\"en\")"
   ],
   "metadata": {
    "id": "q5FUCNmX7ICr"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# Define your query\n",
    "query = \"the geopolitical history of india and pakistan from the perspective of a chinese\"\n",
    "\n",
    "# Get relevant Wikipedia documents\n",
    "docs = retriever.invoke(query)"
   ],
   "metadata": {
    "id": "i-8sH-w67K8J"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "docs"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6mD3zUptQSQg",
    "outputId": "fef2eef8-e15c-487f-e155-10d3e3e89541"
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[Document(metadata={'title': 'India–Pakistan war of 1965', 'summary': \"The India–Pakistan war of 1965, also known as  the second Kashmir war, was an armed conflict between Pakistan and India that took place from August 1965 to September 1965. The conflict began following Pakistan's unsuccessful Operation Gibraltar, which was designed to infiltrate forces into Jammu and Kashmir to precipitate an insurgency against Indian rule. The seventeen day war caused thousands of casualties on both sides and witnessed the largest engagement of armoured vehicles and the largest tank battle since World War II. Hostilities between the two countries ended after a ceasefire was declared through UNSC Resolution 211 following a diplomatic intervention by the Soviet Union and the United States, and the subsequent issuance of the Tashkent Declaration. Much of the war was fought by the countries' land forces in Kashmir and along the border between India and Pakistan. This war saw the largest amassing of troops in Kashmir since the Partition of India in 1947, a number that was overshadowed only during the 2001–2002 military standoff between India and Pakistan. Most of the battles were fought by opposing infantry and armoured units, with substantial backing from air forces, and naval operations.\\nIndia had the upper hand over Pakistan on the ground when the ceasefire was declared, but the PAF managed to achieve air superiority over the combat zones despite being numerically inferior. Although the two countries fought to a standoff, the conflict is seen as a strategic and political defeat for Pakistan, as it had not succeeded in fomenting an insurrection in Kashmir and was instead forced to shift gears in the defence of Lahore. India also failed to achieve its objective of military deterrence and did not capitalise on its advantageous military situation before the ceasefire was declared.\", 'source': 'https://en.wikipedia.org/wiki/India%E2%80%93Pakistan_war_of_1965'}, page_content=\"The India–Pakistan war of 1965, also known as  the second Kashmir war, was an armed conflict between Pakistan and India that took place from August 1965 to September 1965. The conflict began following Pakistan's unsuccessful Operation Gibraltar, which was designed to infiltrate forces into Jammu and Kashmir to precipitate an insurgency against Indian rule. The seventeen day war caused thousands of casualties on both sides and witnessed the largest engagement of armoured vehicles and the largest tank battle since World War II. Hostilities between the two countries ended after a ceasefire was declared through UNSC Resolution 211 following a diplomatic intervention by the Soviet Union and the United States, and the subsequent issuance of the Tashkent Declaration. Much of the war was fought by the countries' land forces in Kashmir and along the border between India and Pakistan. This war saw the largest amassing of troops in Kashmir since the Partition of India in 1947, a number that was overshadowed only during the 2001–2002 military standoff between India and Pakistan. Most of the battles were fought by opposing infantry and armoured units, with substantial backing from air forces, and naval operations.\\nIndia had the upper hand over Pakistan on the ground when the ceasefire was declared, but the PAF managed to achieve air superiority over the combat zones despite being numerically inferior. Although the two countries fought to a standoff, the conflict is seen as a strategic and political defeat for Pakistan, as it had not succeeded in fomenting an insurrection in Kashmir and was instead forced to shift gears in the defence of Lahore. India also failed to achieve its objective of military deterrence and did not capitalise on its advantageous military situation before the ceasefire was declared.\\n\\n\\n== Background ==\\nSince the partition of British India in August 1947, Pakistan and India remained in contention over several issues. Although the Kashmir conflict was the predominant issue dividing the nations, other border disputes existed, most notably over the Rann of Kutch, a barren region in the Indian state of Gujarat. The issue first arose in 1956, which ended with India regaining control over the disputed area. In the 1960s Pakistan received 700 million dollars of military aid from the United States, by signing a defence agreement in 1954, which significantly modernised Pakistan's military equipment. After the defeat in 1962 Sino-Indian War, the Indian military was undergoing major changes in personnel and equipment. During this period, despite being numerically smaller than the Indian military, Pakistan's armed forces had a qualitative edge in air power and armour over India, which Pakistan sought to use before India completed its defence build-up.\\n\\nPakistani soldiers began patrolling in territory controlled by India in January 1965, which was followed by attacks by both countries on each other's posts on 8 April 1965. Initially involving border police from both nations, the disputed area soon witnessed intermittent skirmishes between the countries' armed forces. Pakistan launched Operation Desert Hawk and captured a few Indian posts near the Kanjarkot fort border area. In June 1965, British Prime Minister Harold Wilson successfully persuaded both countries to end hostilities. Both countries signed an agreement to settle the disputed border through international arbitration by the International Court of Justice on 30 June 1965. A tribunal was set to resolve the dispute, the verdict which came later in 1968, saw Pakistan awarded 780 square kilometres (301 square miles) of the Rann of Kutch, as against its original claim of 9,100 km2 (3,500 sq mi). Pakistan's purpose for this operation was to assess the response of the Indian government and military and to draw Indian armour southward to Kutch, away from the Punjab and Kashmir region.\\nAfter its success in the Rann of Kutch, Pakistan, under the leadership of Muhammad Ayub Khan, bel\"),\n",
       " Document(metadata={'title': 'India–Pakistan wars and conflicts', 'summary': 'Since the partition of British India in 1947 and subsequent creation of the dominions of India and Pakistan, the two countries have been involved in a number of wars, conflicts, and military standoffs. A long-running dispute over Kashmir and cross-border terrorism have been the predominant cause of conflict between the two states, with the exception of the Indo-Pakistani War of 1971, which occurred as a direct result of hostilities stemming from the Bangladesh Liberation War in erstwhile East Pakistan (now Bangladesh).\\n\\n', 'source': 'https://en.wikipedia.org/wiki/India%E2%80%93Pakistan_wars_and_conflicts'}, page_content='Since the partition of British India in 1947 and subsequent creation of the dominions of India and Pakistan, the two countries have been involved in a number of wars, conflicts, and military standoffs. A long-running dispute over Kashmir and cross-border terrorism have been the predominant cause of conflict between the two states, with the exception of the Indo-Pakistani War of 1971, which occurred as a direct result of hostilities stemming from the Bangladesh Liberation War in erstwhile East Pakistan (now Bangladesh).\\n\\n\\n== Background ==\\n\\nThe Partition of India came in 1947 with the sudden grant of independence. It was the intention of those who wished for a Muslim state to have a clean partition between independent and equal \"Pakistan\" and \"Hindustan\" once independence came.\\nNearly one third of the Muslim population of India remained in the new India.\\nInter-communal violence between Hindus, Sikhs and Muslims resulted in between 200,000 and 2 million casualties leaving 14 million people displaced.\\nPrincely states in India were provided with an Instrument of Accession to accede to either India or Pakistan.\\n\\n\\n== Wars ==\\n\\n\\n=== Indo-Pakistani war of 1947–1948 ===\\n\\nThe war, also called the first Indo-Pakistani war, started in October 1947 when Pakistan feared that the Maharaja of the princely state of Kashmir and Jammu would accede to India. Following partition, princely states were left to choose whether to join India or Pakistan or to remain independent. Jammu and Kashmir, the largest of the princely states, had a majority Muslim population and significant fraction of Hindu population, all ruled by the Hindu Maharaja Hari Singh. Tribal Islamic forces with support from the army of Pakistan attacked and occupied parts of the princely state forcing the Maharaja to sign the Instrument of Accession of the princely state to the Dominion of India to receive Indian military aid. The UN Security Council passed Resolution 47 on 22 April 1948. The fronts solidified gradually along what came to be known as the Line of Control. A formal cease-fire was declared at 23:59 on the night of 1 January 1949. India gained control of about two-thirds of the state (Kashmir Valley, Jammu and Ladakh) whereas Pakistan gained roughly a third of Kashmir (Azad Kashmir, and Gilgit-Baltistan). The Pakistan controlled areas are collectively referred to as Pakistan administered Kashmir.\\n\\n\\n=== Indo-Pakistani war of 1965 ===\\n\\nThis war started following Pakistan\\'s Operation Gibraltar, which was designed to infiltrate forces into Jammu and Kashmir to precipitate an insurgency against rule by India. India retaliated by launching a full-scale military attack on West Pakistan. The seventeen-day war caused thousands of casualties on both sides and witnessed the largest engagement of armored vehicles and the largest tank battle since World War II. The hostilities between the two countries ended after a ceasefire was declared following diplomatic intervention by the Soviet Union and USA and the subsequent issuance of the Tashkent Declaration. India had the upper hand over Pakistan when the ceasefire was declared.\\n\\n\\n=== Indo-Pakistani war of 1971 ===\\n\\nThis war was unique in the way that it did not involve the issue of Kashmir, but was rather precipitated by the crisis created by the political battle brewing in erstwhile East Pakistan (now Bangladesh) between Sheikh Mujibur Rahman, Leader of East Pakistan, and Yahya Khan and Zulfikar Ali Bhutto, leaders of West Pakistan. This would culminate in the declaration of Independence of Bangladesh from the state system of Pakistan. Following Operation Searchlight and the 1971 Bangladesh atrocities, about 10 million Bengalis in East Pakistan took refuge in neighbouring India.\\nIndia intervened in the ongoing Bangladesh liberation movement. After a large scale pre-emptive strike by Pakistan, full-scale hostilities between the two countries commenced.\\nPakistan attacked at several places along India\\'s western border with Pakistan, but th')]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Print retrieved content\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"\\n--- Result {i+1} ---\")\n",
    "    print(f\"Content:\\n{doc.page_content}...\")  # truncate for display"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UH3lPwDi7Myp",
    "outputId": "a6b12764-cff9-4d94-e4dc-f62ae0244e13"
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "--- Result 1 ---\n",
      "Content:\n",
      "The India–Pakistan war of 1965, also known as  the second Kashmir war, was an armed conflict between Pakistan and India that took place from August 1965 to September 1965. The conflict began following Pakistan's unsuccessful Operation Gibraltar, which was designed to infiltrate forces into Jammu and Kashmir to precipitate an insurgency against Indian rule. The seventeen day war caused thousands of casualties on both sides and witnessed the largest engagement of armoured vehicles and the largest tank battle since World War II. Hostilities between the two countries ended after a ceasefire was declared through UNSC Resolution 211 following a diplomatic intervention by the Soviet Union and the United States, and the subsequent issuance of the Tashkent Declaration. Much of the war was fought by the countries' land forces in Kashmir and along the border between India and Pakistan. This war saw the largest amassing of troops in Kashmir since the Partition of India in 1947, a number that was overshadowed only during the 2001–2002 military standoff between India and Pakistan. Most of the battles were fought by opposing infantry and armoured units, with substantial backing from air forces, and naval operations.\n",
      "India had the upper hand over Pakistan on the ground when the ceasefire was declared, but the PAF managed to achieve air superiority over the combat zones despite being numerically inferior. Although the two countries fought to a standoff, the conflict is seen as a strategic and political defeat for Pakistan, as it had not succeeded in fomenting an insurrection in Kashmir and was instead forced to shift gears in the defence of Lahore. India also failed to achieve its objective of military deterrence and did not capitalise on its advantageous military situation before the ceasefire was declared.\n",
      "\n",
      "\n",
      "== Background ==\n",
      "Since the partition of British India in August 1947, Pakistan and India remained in contention over several issues. Although the Kashmir conflict was the predominant issue dividing the nations, other border disputes existed, most notably over the Rann of Kutch, a barren region in the Indian state of Gujarat. The issue first arose in 1956, which ended with India regaining control over the disputed area. In the 1960s Pakistan received 700 million dollars of military aid from the United States, by signing a defence agreement in 1954, which significantly modernised Pakistan's military equipment. After the defeat in 1962 Sino-Indian War, the Indian military was undergoing major changes in personnel and equipment. During this period, despite being numerically smaller than the Indian military, Pakistan's armed forces had a qualitative edge in air power and armour over India, which Pakistan sought to use before India completed its defence build-up.\n",
      "\n",
      "Pakistani soldiers began patrolling in territory controlled by India in January 1965, which was followed by attacks by both countries on each other's posts on 8 April 1965. Initially involving border police from both nations, the disputed area soon witnessed intermittent skirmishes between the countries' armed forces. Pakistan launched Operation Desert Hawk and captured a few Indian posts near the Kanjarkot fort border area. In June 1965, British Prime Minister Harold Wilson successfully persuaded both countries to end hostilities. Both countries signed an agreement to settle the disputed border through international arbitration by the International Court of Justice on 30 June 1965. A tribunal was set to resolve the dispute, the verdict which came later in 1968, saw Pakistan awarded 780 square kilometres (301 square miles) of the Rann of Kutch, as against its original claim of 9,100 km2 (3,500 sq mi). Pakistan's purpose for this operation was to assess the response of the Indian government and military and to draw Indian armour southward to Kutch, away from the Punjab and Kashmir region.\n",
      "After its success in the Rann of Kutch, Pakistan, under the leadership of Muhammad Ayub Khan, bel...\n",
      "\n",
      "--- Result 2 ---\n",
      "Content:\n",
      "Since the partition of British India in 1947 and subsequent creation of the dominions of India and Pakistan, the two countries have been involved in a number of wars, conflicts, and military standoffs. A long-running dispute over Kashmir and cross-border terrorism have been the predominant cause of conflict between the two states, with the exception of the Indo-Pakistani War of 1971, which occurred as a direct result of hostilities stemming from the Bangladesh Liberation War in erstwhile East Pakistan (now Bangladesh).\n",
      "\n",
      "\n",
      "== Background ==\n",
      "\n",
      "The Partition of India came in 1947 with the sudden grant of independence. It was the intention of those who wished for a Muslim state to have a clean partition between independent and equal \"Pakistan\" and \"Hindustan\" once independence came.\n",
      "Nearly one third of the Muslim population of India remained in the new India.\n",
      "Inter-communal violence between Hindus, Sikhs and Muslims resulted in between 200,000 and 2 million casualties leaving 14 million people displaced.\n",
      "Princely states in India were provided with an Instrument of Accession to accede to either India or Pakistan.\n",
      "\n",
      "\n",
      "== Wars ==\n",
      "\n",
      "\n",
      "=== Indo-Pakistani war of 1947–1948 ===\n",
      "\n",
      "The war, also called the first Indo-Pakistani war, started in October 1947 when Pakistan feared that the Maharaja of the princely state of Kashmir and Jammu would accede to India. Following partition, princely states were left to choose whether to join India or Pakistan or to remain independent. Jammu and Kashmir, the largest of the princely states, had a majority Muslim population and significant fraction of Hindu population, all ruled by the Hindu Maharaja Hari Singh. Tribal Islamic forces with support from the army of Pakistan attacked and occupied parts of the princely state forcing the Maharaja to sign the Instrument of Accession of the princely state to the Dominion of India to receive Indian military aid. The UN Security Council passed Resolution 47 on 22 April 1948. The fronts solidified gradually along what came to be known as the Line of Control. A formal cease-fire was declared at 23:59 on the night of 1 January 1949. India gained control of about two-thirds of the state (Kashmir Valley, Jammu and Ladakh) whereas Pakistan gained roughly a third of Kashmir (Azad Kashmir, and Gilgit-Baltistan). The Pakistan controlled areas are collectively referred to as Pakistan administered Kashmir.\n",
      "\n",
      "\n",
      "=== Indo-Pakistani war of 1965 ===\n",
      "\n",
      "This war started following Pakistan's Operation Gibraltar, which was designed to infiltrate forces into Jammu and Kashmir to precipitate an insurgency against rule by India. India retaliated by launching a full-scale military attack on West Pakistan. The seventeen-day war caused thousands of casualties on both sides and witnessed the largest engagement of armored vehicles and the largest tank battle since World War II. The hostilities between the two countries ended after a ceasefire was declared following diplomatic intervention by the Soviet Union and USA and the subsequent issuance of the Tashkent Declaration. India had the upper hand over Pakistan when the ceasefire was declared.\n",
      "\n",
      "\n",
      "=== Indo-Pakistani war of 1971 ===\n",
      "\n",
      "This war was unique in the way that it did not involve the issue of Kashmir, but was rather precipitated by the crisis created by the political battle brewing in erstwhile East Pakistan (now Bangladesh) between Sheikh Mujibur Rahman, Leader of East Pakistan, and Yahya Khan and Zulfikar Ali Bhutto, leaders of West Pakistan. This would culminate in the declaration of Independence of Bangladesh from the state system of Pakistan. Following Operation Searchlight and the 1971 Bangladesh atrocities, about 10 million Bengalis in East Pakistan took refuge in neighbouring India.\n",
      "India intervened in the ongoing Bangladesh liberation movement. After a large scale pre-emptive strike by Pakistan, full-scale hostilities between the two countries commenced.\n",
      "Pakistan attacked at several places along India's western border with Pakistan, but th...\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Vector Store Retriever"
   ],
   "metadata": {
    "id": "Z2qt9J157djt"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.documents import Document"
   ],
   "metadata": {
    "id": "sUKzoti97OKc"
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 1: Your source documents\n",
    "documents = [\n",
    "    Document(page_content=\"LangChain helps developers build LLM applications easily.\"),\n",
    "    Document(page_content=\"Chroma is a vector database optimized for LLM-based search.\"),\n",
    "    Document(page_content=\"Embeddings convert text into high-dimensional vectors.\"),\n",
    "    Document(page_content=\"OpenAI provides powerful embedding models.\"),\n",
    "]"
   ],
   "metadata": {
    "id": "dLymTTcA7nbZ"
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 2: Initialize embedding model\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "\n",
    "# Step 3: Create Chroma vector store in memory\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embedding_model,\n",
    "    collection_name=\"my_collection\"\n",
    ")"
   ],
   "metadata": {
    "id": "B5J0HYsr7prG",
    "outputId": "805aa312-8054-4503-a1db-c3bed49a3c08",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    }
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "error",
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-**********************************************************************KrkA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'code': 'invalid_api_key', 'param': None}, 'status': 401}",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAuthenticationError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipython-input-2781608688.py\u001B[0m in \u001B[0;36m<cell line: 0>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;31m# Step 3: Create Chroma vector store in memory\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m vectorstore = Chroma.from_documents(\n\u001B[0m\u001B[1;32m      6\u001B[0m     \u001B[0mdocuments\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdocuments\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m     \u001B[0membedding\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0membedding_model\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/langchain_community/vectorstores/chroma.py\u001B[0m in \u001B[0;36mfrom_documents\u001B[0;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001B[0m\n\u001B[1;32m    885\u001B[0m         \u001B[0mtexts\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mdoc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpage_content\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mdoc\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mdocuments\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    886\u001B[0m         \u001B[0mmetadatas\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mdoc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmetadata\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mdoc\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mdocuments\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 887\u001B[0;31m         return cls.from_texts(\n\u001B[0m\u001B[1;32m    888\u001B[0m             \u001B[0mtexts\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtexts\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    889\u001B[0m             \u001B[0membedding\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0membedding\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/langchain_community/vectorstores/chroma.py\u001B[0m in \u001B[0;36mfrom_texts\u001B[0;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001B[0m\n\u001B[1;32m    841\u001B[0m                 \u001B[0mdocuments\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtexts\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    842\u001B[0m             ):\n\u001B[0;32m--> 843\u001B[0;31m                 chroma_collection.add_texts(\n\u001B[0m\u001B[1;32m    844\u001B[0m                     \u001B[0mtexts\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbatch\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mbatch\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    845\u001B[0m                     \u001B[0mmetadatas\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbatch\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mbatch\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/langchain_community/vectorstores/chroma.py\u001B[0m in \u001B[0;36madd_texts\u001B[0;34m(self, texts, metadatas, ids, **kwargs)\u001B[0m\n\u001B[1;32m    275\u001B[0m         \u001B[0mtexts\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtexts\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    276\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_embedding_function\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 277\u001B[0;31m             \u001B[0membeddings\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_embedding_function\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0membed_documents\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtexts\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    278\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mmetadatas\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    279\u001B[0m             \u001B[0;31m# fill metadatas with empty dicts if somebody\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/langchain_openai/embeddings/base.py\u001B[0m in \u001B[0;36membed_documents\u001B[0;34m(self, texts, chunk_size, **kwargs)\u001B[0m\n\u001B[1;32m    707\u001B[0m         \u001B[0;31m# This could be optimized to avoid double work when all texts are short enough.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    708\u001B[0m         \u001B[0mengine\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcast\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdeployment\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 709\u001B[0;31m         return self._get_len_safe_embeddings(\n\u001B[0m\u001B[1;32m    710\u001B[0m             \u001B[0mtexts\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mengine\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mengine\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mchunk_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mchunk_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    711\u001B[0m         )\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/langchain_openai/embeddings/base.py\u001B[0m in \u001B[0;36m_get_len_safe_embeddings\u001B[0;34m(self, texts, engine, chunk_size, **kwargs)\u001B[0m\n\u001B[1;32m    574\u001B[0m             \u001B[0;31m# Make API call with this batch\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    575\u001B[0m             \u001B[0mbatch_tokens\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtokens\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0mbatch_end\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 576\u001B[0;31m             \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclient\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcreate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbatch_tokens\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mclient_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    577\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresponse\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdict\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    578\u001B[0m                 \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mresponse\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel_dump\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/openai/resources/embeddings.py\u001B[0m in \u001B[0;36mcreate\u001B[0;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001B[0m\n\u001B[1;32m    130\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mobj\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    131\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 132\u001B[0;31m         return self._post(\n\u001B[0m\u001B[1;32m    133\u001B[0m             \u001B[0;34m\"/embeddings\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    134\u001B[0m             \u001B[0mbody\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmaybe_transform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0membedding_create_params\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mEmbeddingCreateParams\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001B[0m in \u001B[0;36mpost\u001B[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1257\u001B[0m             \u001B[0mmethod\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"post\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0murl\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mjson_data\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbody\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfiles\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mto_httpx_files\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfiles\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1258\u001B[0m         )\n\u001B[0;32m-> 1259\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mcast\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mResponseT\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcast_to\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mopts\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstream\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstream\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstream_cls\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstream_cls\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1260\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1261\u001B[0m     def patch(\n",
      "\u001B[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001B[0m in \u001B[0;36mrequest\u001B[0;34m(self, cast_to, options, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1045\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1046\u001B[0m                 \u001B[0mlog\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdebug\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Re-raising status error\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1047\u001B[0;31m                 \u001B[0;32mraise\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_make_status_error_from_response\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0merr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresponse\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1048\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1049\u001B[0m             \u001B[0;32mbreak\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAuthenticationError\u001B[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-**********************************************************************KrkA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'code': 'invalid_api_key', 'param': None}, 'status': 401}"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 4: Convert vectorstore into a retriever\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})"
   ],
   "metadata": {
    "id": "xvSgoUYs7sLu"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "query = \"What is Chroma used for?\"\n",
    "results = retriever.invoke(query)"
   ],
   "metadata": {
    "id": "I5l0rXl67v4N"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for i, doc in enumerate(results):\n",
    "    print(f\"\\n--- Result {i+1} ---\")\n",
    "    print(doc.page_content)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OMAEeCxK7yRR",
    "outputId": "7f140c90-bf2d-4d54-8988-813b74ed281b"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "--- Result 1 ---\n",
      "Chroma is a vector database optimized for LLM-based search.\n",
      "\n",
      "--- Result 2 ---\n",
      "LangChain helps developers build LLM applications easily.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "results = vectorstore.similarity_search(query, k=2)"
   ],
   "metadata": {
    "id": "hh0zC7L6R1Zn"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for i, doc in enumerate(results):\n",
    "    print(f\"\\n--- Result {i+1} ---\")\n",
    "    print(doc.page_content)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J7kYMau5R1sC",
    "outputId": "d7b05617-45d7-4584-d18a-a578e4a28e89"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "--- Result 1 ---\n",
      "Chroma is a vector database optimized for LLM-based search.\n",
      "\n",
      "--- Result 2 ---\n",
      "LangChain helps developers build LLM applications easily.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MMR"
   ],
   "metadata": {
    "id": "zDwJT1x9A2tI"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Sample documents\n",
    "docs = [\n",
    "    Document(page_content=\"LangChain makes it easy to work with LLMs.\"),\n",
    "    Document(page_content=\"LangChain is used to build LLM based applications.\"),\n",
    "    Document(page_content=\"Chroma is used to store and search document embeddings.\"),\n",
    "    Document(page_content=\"Embeddings are vector representations of text.\"),\n",
    "    Document(page_content=\"MMR helps you get diverse results when doing similarity search.\"),\n",
    "    Document(page_content=\"LangChain supports Chroma, FAISS, Pinecone, and more.\"),\n",
    "]"
   ],
   "metadata": {
    "id": "8uL8bET570ud"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Initialize OpenAI embeddings\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "\n",
    "# Step 2: Create the FAISS vector store from documents\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embedding_model\n",
    ")"
   ],
   "metadata": {
    "id": "TM7GvqKeA8ml"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Enable MMR in the retriever\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",                   # <-- This enables MMR\n",
    "    search_kwargs={\"k\": 3, \"lambda_mult\": 0.5}  # k = top results, lambda_mult = relevance-diversity balance\n",
    ")"
   ],
   "metadata": {
    "id": "ueDg6SApBAqt"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "query = \"What is langchain?\"\n",
    "results = retriever.invoke(query)"
   ],
   "metadata": {
    "id": "52AkKNz7Chcf"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for i, doc in enumerate(results):\n",
    "    print(f\"\\n--- Result {i+1} ---\")\n",
    "    print(doc.page_content)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H-HvthKyCkBL",
    "outputId": "6bec200b-9541-480f-fa94-1b8c6b3174f2"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "--- Result 1 ---\n",
      "LangChain is used to build LLM based applications.\n",
      "\n",
      "--- Result 2 ---\n",
      "Embeddings are vector representations of text.\n",
      "\n",
      "--- Result 3 ---\n",
      "LangChain supports Chroma, FAISS, Pinecone, and more.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Multiquery Retriever"
   ],
   "metadata": {
    "id": "HFybBaL-Eu8-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever"
   ],
   "metadata": {
    "id": "Djm-59wI1J-s"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Relevant health & wellness documents\n",
    "all_docs = [\n",
    "    Document(page_content=\"Regular walking boosts heart health and can reduce symptoms of depression.\", metadata={\"source\": \"H1\"}),\n",
    "    Document(page_content=\"Consuming leafy greens and fruits helps detox the body and improve longevity.\", metadata={\"source\": \"H2\"}),\n",
    "    Document(page_content=\"Deep sleep is crucial for cellular repair and emotional regulation.\", metadata={\"source\": \"H3\"}),\n",
    "    Document(page_content=\"Mindfulness and controlled breathing lower cortisol and improve mental clarity.\", metadata={\"source\": \"H4\"}),\n",
    "    Document(page_content=\"Drinking sufficient water throughout the day helps maintain metabolism and energy.\", metadata={\"source\": \"H5\"}),\n",
    "    Document(page_content=\"The solar energy system in modern homes helps balance electricity demand.\", metadata={\"source\": \"I1\"}),\n",
    "    Document(page_content=\"Python balances readability with power, making it a popular system design language.\", metadata={\"source\": \"I2\"}),\n",
    "    Document(page_content=\"Photosynthesis enables plants to produce energy by converting sunlight.\", metadata={\"source\": \"I3\"}),\n",
    "    Document(page_content=\"The 2022 FIFA World Cup was held in Qatar and drew global energy and excitement.\", metadata={\"source\": \"I4\"}),\n",
    "    Document(page_content=\"Black holes bend spacetime and store immense gravitational energy.\", metadata={\"source\": \"I5\"}),\n",
    "]"
   ],
   "metadata": {
    "id": "Vxr_cxaJ1KQV"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Initialize OpenAI embeddings\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "\n",
    "# Create FAISS vector store\n",
    "vectorstore = FAISS.from_documents(documents=all_docs, embedding=embedding_model)"
   ],
   "metadata": {
    "id": "pq6eouD41KfF"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Create retrievers\n",
    "similarity_retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})"
   ],
   "metadata": {
    "id": "kh62ZNvD1Krv"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "multiquery_retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 5}),\n",
    "    llm=ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    ")"
   ],
   "metadata": {
    "id": "vXUHDW6m1K75"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Query\n",
    "query = \"How to improve energy levels and maintain balance?\""
   ],
   "metadata": {
    "id": "9ybExIQQ1bnt"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Retrieve results\n",
    "similarity_results = similarity_retriever.invoke(query)\n",
    "multiquery_results= multiquery_retriever.invoke(query)"
   ],
   "metadata": {
    "id": "V2SlmAoi1gOP"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for i, doc in enumerate(similarity_results):\n",
    "    print(f\"\\n--- Result {i+1} ---\")\n",
    "    print(doc.page_content)\n",
    "\n",
    "print(\"*\"*150)\n",
    "\n",
    "for i, doc in enumerate(multiquery_results):\n",
    "    print(f\"\\n--- Result {i+1} ---\")\n",
    "    print(doc.page_content)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yQUtMLupwfe2",
    "outputId": "743431a3-5b0e-4f69-8af3-dec66a49f7ce"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "--- Result 1 ---\n",
      "Drinking sufficient water throughout the day helps maintain metabolism and energy.\n",
      "\n",
      "--- Result 2 ---\n",
      "Mindfulness and controlled breathing lower cortisol and improve mental clarity.\n",
      "\n",
      "--- Result 3 ---\n",
      "Regular walking boosts heart health and can reduce symptoms of depression.\n",
      "\n",
      "--- Result 4 ---\n",
      "Deep sleep is crucial for cellular repair and emotional regulation.\n",
      "\n",
      "--- Result 5 ---\n",
      "The solar energy system in modern homes helps balance electricity demand.\n",
      "******************************************************************************************************************************************************\n",
      "\n",
      "--- Result 1 ---\n",
      "Drinking sufficient water throughout the day helps maintain metabolism and energy.\n",
      "\n",
      "--- Result 2 ---\n",
      "Mindfulness and controlled breathing lower cortisol and improve mental clarity.\n",
      "\n",
      "--- Result 3 ---\n",
      "Regular walking boosts heart health and can reduce symptoms of depression.\n",
      "\n",
      "--- Result 4 ---\n",
      "Consuming leafy greens and fruits helps detox the body and improve longevity.\n",
      "\n",
      "--- Result 5 ---\n",
      "Deep sleep is crucial for cellular repair and emotional regulation.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ContextualCompressionRetriever"
   ],
   "metadata": {
    "id": "6AP7o9-VJ0Zq"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain_core.documents import Document"
   ],
   "metadata": {
    "id": "RVl6n3HH6gp_"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Recreate the document objects from the previous data\n",
    "docs = [\n",
    "    Document(page_content=(\n",
    "        \"\"\"The Grand Canyon is one of the most visited natural wonders in the world.\n",
    "        Photosynthesis is the process by which green plants convert sunlight into energy.\n",
    "        Millions of tourists travel to see it every year. The rocks date back millions of years.\"\"\"\n",
    "    ), metadata={\"source\": \"Doc1\"}),\n",
    "\n",
    "    Document(page_content=(\n",
    "        \"\"\"In medieval Europe, castles were built primarily for defense.\n",
    "        The chlorophyll in plant cells captures sunlight during photosynthesis.\n",
    "        Knights wore armor made of metal. Siege weapons were often used to breach castle walls.\"\"\"\n",
    "    ), metadata={\"source\": \"Doc2\"}),\n",
    "\n",
    "    Document(page_content=(\n",
    "        \"\"\"Basketball was invented by Dr. James Naismith in the late 19th century.\n",
    "        It was originally played with a soccer ball and peach baskets. NBA is now a global league.\"\"\"\n",
    "    ), metadata={\"source\": \"Doc3\"}),\n",
    "\n",
    "    Document(page_content=(\n",
    "        \"\"\"The history of cinema began in the late 1800s. Silent films were the earliest form.\n",
    "        Thomas Edison was among the pioneers. Photosynthesis does not occur in animal cells.\n",
    "        Modern filmmaking involves complex CGI and sound design.\"\"\"\n",
    "    ), metadata={\"source\": \"Doc4\"})\n",
    "]"
   ],
   "metadata": {
    "id": "RmLD6aZB6g1k"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Create a FAISS vector store from the documents\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(docs, embedding_model)"
   ],
   "metadata": {
    "id": "tgMNKHnv6hD8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "base_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})"
   ],
   "metadata": {
    "id": "vlAqc8lQrz_B"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Set up the compressor using an LLM\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "compressor = LLMChainExtractor.from_llm(llm)"
   ],
   "metadata": {
    "id": "nHjUdgiS6hRK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Create the contextual compression retriever\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_retriever=base_retriever,\n",
    "    base_compressor=compressor\n",
    ")"
   ],
   "metadata": {
    "id": "um5gKEMT6hdB"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Query the retriever\n",
    "query = \"What is photosynthesis?\"\n",
    "compressed_results = compression_retriever.invoke(query)"
   ],
   "metadata": {
    "id": "lmHGenTo6hp6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for i, doc in enumerate(compressed_results):\n",
    "    print(f\"\\n--- Result {i+1} ---\")\n",
    "    print(doc.page_content)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SyIUYw035g0c",
    "outputId": "99a654d5-9239-4912-fd3e-4130c00b115a"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "--- Result 1 ---\n",
      "Photosynthesis is the process by which green plants convert sunlight into energy.\n",
      "\n",
      "--- Result 2 ---\n",
      "The chlorophyll in plant cells captures sunlight during photosynthesis.\n"
     ]
    }
   ]
  }
 ]
}
